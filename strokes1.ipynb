{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline #display plots inline\n",
    "\n",
    "#import packages\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "#load dataset\n",
    "df = pd.read_csv(\"stroke_data.csv\")\n",
    "\n",
    "#check for missing values\n",
    "msno.bar(df)\n",
    "fig = plt.figure(figsize=(25, 20))\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.savefig(\"Heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the dataset variables and summary statistics\n",
    "df.info()\n",
    "df.describe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for response categories\n",
    "print(df['gender'].value_counts())\n",
    "\n",
    "#Convert string data to numerical\n",
    "def gender_to_numeric(x):\n",
    "        if x=='Female': return 0\n",
    "        if x=='Male':   return 1\n",
    "\n",
    "df['gender'] = df['gender'].apply(gender_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for response categories\n",
    "print(df['ever_married'].value_counts())\n",
    "\n",
    "#Convert string data to numerical\n",
    "def ever_married_to_numeric(x):\n",
    "        if x=='Yes': return 1\n",
    "        if x=='No':   return 0\n",
    "\n",
    "df['ever_married'] = df['ever_married'].apply(ever_married_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for response categories\n",
    "print(df['Residence_type'].value_counts())\n",
    "\n",
    "#Convert string data to numerical\n",
    "def Residence_type_to_numeric(x):\n",
    "        if x=='Urban': return 1\n",
    "        if x=='Rural':   return 0\n",
    "\n",
    "df['Residence_type'] = df['Residence_type'].apply(Residence_type_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['work_type'].value_counts())\n",
    "import category_encoders as ce\n",
    "encoder=ce.OneHotEncoder(cols='work_type',handle_unknown='return_nan',return_df=True,use_cat_names=True)\n",
    "df = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['smoking_status'].value_counts())\n",
    "encoder=ce.OneHotEncoder(cols='smoking_status',handle_unknown='return_nan',return_df=True,use_cat_names=True)\n",
    "df = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['stroke'].values\n",
    "df_temp = df.copy(deep=True)\n",
    "df_temp.drop('stroke', inplace=True, axis=1)\n",
    "X = df_temp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scl = StandardScaler()\n",
    "std_scl.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "print(\"prediction for datapoint 0:\", model.predict([X[0]]))\n",
    "print(model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y, y_pred)\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print(\"accuracy:\", accuracy_score(y, y_pred))\n",
    "print(\"precision:\", precision_score(y, y_pred))\n",
    "print(\"recall:\", recall_score(y, y_pred))\n",
    "print(\"f1 score:\", f1_score(y, y_pred))\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=None)\n",
    "pca.fit(X)\n",
    "\n",
    "# Get the eigenvalues\n",
    "print(\"Eigenvalues:\")\n",
    "print(pca.explained_variance_)\n",
    "print()\n",
    "\n",
    "# Get explained variances\n",
    "print(\"Variances (Percentage):\")\n",
    "print(pca.explained_variance_ratio_ * 100)\n",
    "print()\n",
    "\n",
    "# Make the scree plot\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_ * 100))\n",
    "plt.xlabel(\"Number of components (Dimensions)\")\n",
    "plt.ylabel(\"Explained variance (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Get the transformed dataset\n",
    "X_pca = pd.DataFrame(X_pca)\n",
    "print(X_pca.head())\n",
    "print(\"\\nSize: \")\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X_pca.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.20, shuffle=True, random_state=2)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(max_iter=2500)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test_pca) # Predictions\n",
    "y_true = y_test # True values\n",
    "\n",
    "# Measure accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "print(\"Train accuracy:\", np.round(accuracy_score(y_train, clf.predict(X_train_pca)), 2))\n",
    "print(\"Test accuracy:\", np.round(accuracy_score(y_true, y_pred), 2))\n",
    "\n",
    "# Make the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nTest confusion_matrix\")\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Construct pipeline\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components=2)\n",
    "log_reg = LogisticRegression(max_iter=2500)\n",
    "\n",
    "log_reg_model = Pipeline([\n",
    "    ('std_scaler', sc),\n",
    "    ('pca', pca),\n",
    "    ('regressor', log_reg)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True, random_state=2)\n",
    "log_reg_model.fit(X_train,y_train)\n",
    "y_pred = log_reg_model.predict(X_test) # Predictions\n",
    "y_true = y_test # True values\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nTest confusion_matrix\")\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print(precision_recall_fscore_support(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)[:, 1] > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nTest confusion_matrix\")\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('1 - specificity')\n",
    "plt.ylabel('sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 AUC score: 0.8210214318285454\n",
      "model 1 AUC score: 0.803776478879078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nimnathw/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred_proba1 = model1.predict_proba(X_test)\n",
    "print(\"model 1 AUC score:\", roc_auc_score(y_test, y_pred_proba1[:, 1]))\n",
    "\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train[:, 0:2], y_train)\n",
    "y_pred_proba2 = model2.predict_proba(X_test[:, 0:2])\n",
    "print(\"model 1 AUC score:\", roc_auc_score(y_test, y_pred_proba2[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
